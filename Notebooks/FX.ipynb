{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQiinpYUWIRP"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9_SAy4E2WIRS",
    "outputId": "63ea507c-9e17-4ec2-9210-af06447ae3fc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario-rtd/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "!pip install -q git+https://github.com/oanda/oandapy.git\n",
    "import oandapy as opy\n",
    "\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chlEJFmXWIRZ"
   },
   "outputs": [],
   "source": [
    "oanda = opy.API(environment='live')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQeSRgw7WIRb"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvFjsxshWIRd"
   },
   "outputs": [],
   "source": [
    "# Input for downloading data using Oanda API\n",
    "d1 = '2007-01-01'\n",
    "d2 = str(dt.now())[:10]\n",
    "instrument = 'USD_JPY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9pK_SL9WIRf"
   },
   "outputs": [],
   "source": [
    "# Download data in chucks\n",
    "dates = pd.date_range(start=d1, end=d2, freq='D')\n",
    "df = pd.DataFrame()\n",
    " \n",
    "for i in range(0, len(dates) -1):\n",
    "    d1 = str(dates[i]).replace(' ', 'T')\n",
    "    d2 = str(dates[i+1]).replace(' ', 'T')\n",
    "     \n",
    "    try:\n",
    "        data = oanda.get_history(instrument=instrument, start=d1, end=d2, granularity='M1')\n",
    "        df = df.append(pd.DataFrame(data['candles']))\n",
    "    except:\n",
    "        pass\n",
    "date = pd.DatetimeIndex(df['time'], tz='UTC')\n",
    "df['date'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjPvGwtUVDse"
   },
   "outputs": [],
   "source": [
    "DF = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wD4JLEsKWIRl"
   },
   "outputs": [],
   "source": [
    "df = df.drop(['complete', 'time', 'closeAsk', 'highAsk', 'lowAsk', 'openAsk'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "2C6MTxlFVTuF",
    "outputId": "ff6d3844-a7bc-46f7-8eec-662316835d2a"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPZs5uvXVaXv"
   },
   "outputs": [],
   "source": [
    "cl = ['Close15', 'Close30', 'Close45']\n",
    "lo = ['Low15', 'Low30', 'Low45']\n",
    "hi = ['High15', 'High30', 'High45']\n",
    "op = ['Open15', 'Open30', 'Open45']\n",
    "shifts = [1,2,3]\n",
    "\n",
    "for i,j,k,o,s in zip(cl,lo,hi,op,shifts):\n",
    "  df[i] = df['closeBid'].shift(s)\n",
    "  df[j] = df['lowBid'].shift(s)\n",
    "  df[k] = df['highBid'].shift(s)\n",
    "  df[o] = df['openBid'].shift(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "5ZiQU7GtWA7Z",
    "outputId": "272ca3fc-eb43-44a2-984a-0bd07777f707"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R29JeFY0c1xZ"
   },
   "outputs": [],
   "source": [
    "df['date'] = df['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZKiyQYIb4m7"
   },
   "outputs": [],
   "source": [
    "df['d2'] = df['date'].str[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcW0NMESazzx"
   },
   "outputs": [],
   "source": [
    "df = df[df['d2'] == '45:00+00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNEE6hAIdX0m"
   },
   "outputs": [],
   "source": [
    "df = df[4:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8ffmn14jk6I"
   },
   "outputs": [],
   "source": [
    "df['H'] = df.drop(['volume', 'date', 'd2'], 1).max(axis=1)\n",
    "df['L'] = df.drop(['volume', 'date', 'd2'], 1).min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "kLi7teRKj7cl",
    "outputId": "b99ab8f8-71ec-4337-8d19-3ff7f4416531"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9JK4yLCWIRp"
   },
   "outputs": [],
   "source": [
    "# DataFrame para regresión lineal a futuros precios\n",
    "dflr = df.copy()\n",
    "# DataFrame para red neuronal (probabilidades) de clasificación\n",
    "dfnn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6WiCWG0jkGY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRdavRSrWIRr"
   },
   "source": [
    "# Regresión Lineal (Pronóstico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2sD_5U0WWIRs"
   },
   "outputs": [],
   "source": [
    "LRresponsesBid = ['FutureClose', 'FutureHigh', 'FutureLow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDz2c1fKWIRw"
   },
   "outputs": [],
   "source": [
    "LRactualBid = ['closeBid', 'H', 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "PDlTVl-fWIR0",
    "outputId": "6204b8e6-dab1-4648-fabf-0a16d483f308"
   },
   "outputs": [],
   "source": [
    "dflr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yjy5EwENjuDT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rT-_qaYRWIR3"
   },
   "outputs": [],
   "source": [
    "for j,l in zip(LRresponsesBid, LRactualBid):\n",
    "    dflr[j] = dflr[l].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqORwCreWIR6"
   },
   "outputs": [],
   "source": [
    "dflr['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "1fqsR2I5WIR_",
    "outputId": "32c6507a-6303-4cce-a634-2cc176a54c52"
   },
   "outputs": [],
   "source": [
    "dflr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0do584eWISJ"
   },
   "outputs": [],
   "source": [
    "def augment_data(DF, response, correl=0.1, datetrans=False, convertdummies=False, dummy_transform=False):\n",
    "    \"\"\"\n",
    "    Prueba ciertas transformaciones numéricas y verifica si la correlación es buena\n",
    "    para agregarlas al dataframe\n",
    "    \n",
    "    Args:\n",
    "        DF (DataFrame): DataFrame de tus datos\n",
    "        response (str): Variable dependiente (la debe contener tu base)\n",
    "        correl (float): Correlación mínima que se espera de una variable que \n",
    "                        quieres que entre al modelo\n",
    "        convertdummies (boolean): Si queremos convertir categóricas a variables\n",
    "                                  binarias\n",
    "        dummy_transform (boolean): Si queremos encontrar transformaciones en las\n",
    "                                   variables binarias\n",
    "    Returns:\n",
    "        df (DataFrame): DataFrame con transformaciones útiles\n",
    "    \n",
    "    \"\"\"\n",
    "    df = DF.copy()\n",
    "    \n",
    "    numericas = list(df.select_dtypes(include=['int','float']).columns) \n",
    "    fechas = list(df.select_dtypes(include=['datetime']).columns)\n",
    "\n",
    "    numericas = [x for x in numericas if x != response]\n",
    "    fechas = [x for x in fechas if x != response]\n",
    "    \n",
    "    newvars = []\n",
    "    unuseful = []\n",
    "    \n",
    "    if convertdummies != False:\n",
    "        cat = list(df.select_dtypes(include=['category', 'object']).columns) \n",
    "        df = pd.get_dummies(df, columns=cat)\n",
    "    \n",
    "    # En caso de querer transformaciones en nuestras variables binarias hay\n",
    "    # un gran tiempo de espera\n",
    "    if dummy_transform != False:\n",
    "        dummy_vars = []\n",
    "        for i in df.columns:\n",
    "            if set(df[i].unique()) == set([0, 1]):\n",
    "                dummy_vars.append(i)\n",
    "        \n",
    "        dummy_vars = [x for x in dummy_vars if x != response]\n",
    "        fechas = [i for i in fechas if i not in dummy_vars]\n",
    "        numericas = [i for i in numericas if i not in dummy_vars]\n",
    "        \n",
    "        acum = []\n",
    "        for i in dummy_vars:\n",
    "            acum.append(i)\n",
    "            for j in [x for x in dummy_vars if x not in acum]:\n",
    "                # Multiplicación de conectores lógicos (AND)\n",
    "                varname = i + '*' + j\n",
    "                df[varname] = df[i] * df[j]\n",
    "                correlagg = df[[varname, response]].corr()[response][0]\n",
    "                # Se agrega si supera la correlación mínima\n",
    "                if abs(correlagg) > abs(correl):\n",
    "                    newvars.append(varname)\n",
    "                else:\n",
    "                    unuseful.append(varname)\n",
    "    \n",
    "    if datetrans != False:\n",
    "        acum_fechas = []\n",
    "        for i in fechas:\n",
    "            varname = 'hora_' + i\n",
    "            # Hora de la fecha\n",
    "            df[varname] = df[i].dt.hour\n",
    "            correlhora = df[[varname, response]].corr()[response][0]\n",
    "\n",
    "            # Se agrega si supera la correlación mínima\n",
    "            if abs(correlhora) > abs(correl):\n",
    "\n",
    "                newvars.append(varname)\n",
    "            else:\n",
    "                unuseful.append(varname)\n",
    "\n",
    "            varname = 'dia_' + i\n",
    "            # Día de la fecha    \n",
    "            df[varname] = df[i].dt.day\n",
    "            correldia = df[[varname, response]].corr()[response][0]\n",
    "\n",
    "            # Se agrega si supera la correlación mínima\n",
    "            if abs(correldia) > abs(correl):\n",
    "\n",
    "                newvars.append(varname)\n",
    "            else:\n",
    "                unuseful.append(varname)\n",
    "\n",
    "            varname = 'mes_' + i\n",
    "            # Mes de la fecha\n",
    "            df[varname] = df[i].dt.month\n",
    "            correlmes = df[[varname, response]].corr()[response][0]\n",
    "\n",
    "            # Se agrega si supera la correlación mínima\n",
    "            if abs(correlmes) > abs(correl):\n",
    "\n",
    "                newvars.append(varname)\n",
    "            else:\n",
    "                unuseful.append(varname)\n",
    "\n",
    "            acum_fechas.append(i)\n",
    "            for j in [x for x in fechas if x not in acum_fechas]:\n",
    "                # Diferencia de fechas (en días)\n",
    "                varname = i + '-' + j\n",
    "                df.loc[(df[i].notnull()) & (df[j].notnull()), varname] = (df[i] - df[j]).dt.days\n",
    "                correldif = df[[varname, response]].corr()[response][0]\n",
    "                # Se agrega si supera la correlación mínima\n",
    "                if abs(correldif) > abs(correl):\n",
    "                    newvars.append(varname)\n",
    "                else:\n",
    "                    unuseful.append(varname)\n",
    "\n",
    "    for i in numericas:\n",
    "        # Correlación sin transformación\n",
    "        correl1 = df[[i, response]].corr()[response][0]\n",
    "        varname = i + '^' + str(2)\n",
    "        # Variable al cuadrado\n",
    "        df[varname] = df[i]**2\n",
    "        \n",
    "        # Correlación con cada variable al cuadrado\n",
    "        correl2 = df[[varname, response]].corr()[response][0]\n",
    "        # Se agrega si supera la correlación mínima y la correlación sin transformación\n",
    "        if abs(correl2) > abs(correl) and abs(correl2) > abs(correl1):\n",
    "            \n",
    "            newvars.append(varname)\n",
    "        else:\n",
    "            unuseful.append(varname)\n",
    "            \n",
    "        varname = i + '^' + str(3)\n",
    "        # Variable al cubo\n",
    "        df[varname] = df[i]**3\n",
    "        \n",
    "        # Correlación con cada variable al cubo\n",
    "        correl3 = df[[varname, response]].corr()[response][0]\n",
    "        \n",
    "        # Se agrega si supera la correlación mínima y la correlación sin transformación\n",
    "        if abs(correl3) > abs(correl) and abs(correl3) > abs(correl1):\n",
    "            \n",
    "            newvars.append(varname)\n",
    "        else:\n",
    "            unuseful.append(varname)\n",
    "        \n",
    "        varname = 'sqrt(' + i + ')'\n",
    "        # Raíz cuadrada de la variable\n",
    "        df[varname] = np.sqrt(df[i])\n",
    "        \n",
    "        # Correlación con la raíz cuadrada de cada variable\n",
    "        correlsqrt = df[[varname, response]].corr()[response][0]\n",
    "        \n",
    "        # Se agrega si supera la correlación mínima y la correlación sin transformación\n",
    "        if abs(correlsqrt) > abs(correl) and abs(correlsqrt) > abs(correl1):\n",
    "            \n",
    "            newvars.append(varname)\n",
    "        else:\n",
    "            unuseful.append(varname)\n",
    "        \n",
    "        varname = '1/' + i\n",
    "        # Inverso de la variable\n",
    "        df[varname] = 1 / df[i]\n",
    "        \n",
    "        # Correlación con el inverso de cada variable\n",
    "        correlinv = df[[varname, response]].corr()[response][0]\n",
    "        \n",
    "        # Se agrega si supera la correlación mínima y la correlación sin transformación\n",
    "        if abs(correlinv) > abs(correl) and abs(correlinv) > abs(correl1):\n",
    "            \n",
    "            newvars.append(varname)\n",
    "        else:\n",
    "            unuseful.append(varname)\n",
    "        \n",
    "        varname = 'log(' + i + ')' \n",
    "        # Logaritmo de la variable\n",
    "        df[varname] = df[i].apply(np.log)\n",
    "        \n",
    "        # Correlación con el logaritmo de cada variable\n",
    "        correllog = df[[varname, response]].corr()[response][0]\n",
    "        \n",
    "        # Se agrega si supera la correlación mínima y la correlación sin transformación\n",
    "        if abs(correllog) > abs(correl) and abs(correllog) > abs(correl1):\n",
    "            \n",
    "            newvars.append(varname)\n",
    "        else:\n",
    "            unuseful.append(varname)\n",
    "            \n",
    "        varname = '%(' + i + ')' \n",
    "        # Porcentaje con el pasado\n",
    "        df[varname] = df[i].div(df[i].shift(1))\n",
    "   \n",
    "        newvars.append(varname)\n",
    "            \n",
    "        varname = '>' + i \n",
    "        df[varname] = 0\n",
    "        df.loc[df['%(' + i + ')'] >= 1, varname] = 1\n",
    "    \n",
    "        newvars.append(varname)\n",
    "        \n",
    "        for j in range(2,4):\n",
    "            df[i+str(j)] = 0\n",
    "            df[i+str(j)] = df[i].shift(j-1)\n",
    "        \n",
    "    df = df.drop(unuseful, 1)\n",
    "    print('Agregamos las siguientes transformaciones:')\n",
    "    display(newvars)\n",
    "    \n",
    "    df = df.replace(-np.inf, -100000)\n",
    "    df = df.replace(np.inf, 100000)\n",
    "    \n",
    "    num = list(df.select_dtypes(include=['int', 'float']).columns)\n",
    "    \n",
    "    return df[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2339
    },
    "colab_type": "code",
    "id": "-hd82OaaWISP",
    "outputId": "6e29a195-c05a-400c-8b99-320edba2f7af"
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "LRresponses = LRresponsesBid\n",
    "for i in LRresponses:\n",
    "    drop = [k for k in LRresponses if k != i]\n",
    "    dfi = augment_data(dflr.drop(drop, axis=1), i, correl=0.2, \n",
    "                     datetrans=True, convertdummies=False, dummy_transform=False)\n",
    "    dfs.append(dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KoZmC9PlWISU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def train_test(Data, response, time_series=False):\n",
    "    \"\"\"\n",
    "    Regresa train y test sets con el 75% de los datos\n",
    "    para entrenar y el 25% para probar el modelo\n",
    "    \n",
    "    Args:\n",
    "        Data (DataFrame): Datos listos para el modelo\n",
    "        response (str): Variable respuesta\n",
    "        time_series (boolean): Si es serie de tiempo o no\n",
    "    Returns:\n",
    "        X_train (Array): conjunto de datos de entrenamiento (indep)\n",
    "        X_test (Array): conjunto de datos de prueba (indep)\n",
    "        y_train (Array): conjunto de datos de entrenamiento (dep)\n",
    "        y_test (Array): conjunto de datos de prueba (dep)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    Data1 = Data.copy()\n",
    "    X = Data1.drop(response, 1)\n",
    "    y = Data1[response]\n",
    "    \n",
    "    if time_series == True:\n",
    "        tscv = TimeSeriesSplit(n_splits=2)\n",
    "        for train_index, test_index in tscv.split(X):\n",
    "            X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "            y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    \n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n",
    "        X_train = X_train.values\n",
    "        X_test = X_test.values\n",
    "        y_train = y_train.values\n",
    "        y_test = y_test.values\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "n1OgrvIOWISX",
    "outputId": "52483a14-cc46-4809-8eb9-9c372c1d848f"
   },
   "outputs": [],
   "source": [
    "#!pip install statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def linreg_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Calcula modelo de Regresión Logística  \n",
    "    Args:\n",
    "        X_train (Array): conjunto de datos de entrenamiento (indep)\n",
    "        y_train (Array): conjunto de datos de entrenamiento (dep)\n",
    "    returns:\n",
    "        logit (modelo): Regresión Logística\n",
    "\n",
    "    \"\"\"\n",
    "    linreg = sm.OLS(y_train, X_train)\n",
    "    lr = linreg.fit()\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7673
    },
    "colab_type": "code",
    "id": "fs26Zfu4WISZ",
    "outputId": "c836dd03-c178-4fda-c00c-72813662e97b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lrmodels = []\n",
    "for i in range(len(dfs)):\n",
    "    print(LRresponses[i])\n",
    "    dfs[i] = dfs[i].dropna()\n",
    "    X_train, X_test, y_train, y_test = train_test(dfs[i], LRresponses[i], time_series=True)\n",
    "    lr = linreg_model(X_train, y_train)\n",
    "    print(lr.summary())\n",
    "    lrmodels.append(lr)\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.plot(range(len(y_test)),lr.predict(X_test), color='r')\n",
    "    plt.plot(range(len(y_test)),y_test, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-Sv40YmWISd"
   },
   "outputs": [],
   "source": [
    "for i in range(len(lrmodels)):\n",
    "    lrmodels[i].save(LRresponses[i]+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-c7XFB-RWISf"
   },
   "source": [
    "# Red Neuronal (Clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CR1vYNdcWISg"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.models import load_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlya_SXbWISi"
   },
   "outputs": [],
   "source": [
    "NNactualBid = ['closeBid', 'H', 'L']\n",
    "responsenn = ['Labelclose', 'labelhigh', 'labellow']\n",
    "\n",
    "for i,j in zip(NNactualBid, responsenn):\n",
    "    dfnn['return'] = dfnn[i].shift(-1) - dfnn[i]\n",
    "    dfnn[j] = dfnn['return'].apply(lambda x: 1 if x>0.0 else 0)\n",
    "    dfnn = dfnn.drop('return', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "yDKfwYI8l4S3",
    "outputId": "90b36d07-7bf5-4c22-dd1f-cf8d585f01bc"
   },
   "outputs": [],
   "source": [
    "dfnn.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2123
    },
    "colab_type": "code",
    "id": "dsgVoYSGltli",
    "outputId": "b21aa853-503a-4513-d6df-0a2a5eb1d17b"
   },
   "outputs": [],
   "source": [
    "dfsn = []\n",
    "\n",
    "for i in responsenn:\n",
    "    drop = [k for k in responsenn if k != i]\n",
    "    dfi = augment_data(dfnn.drop(drop, axis=1), i, correl=0.2, \n",
    "                     datetrans=True, convertdummies=False, dummy_transform=False)\n",
    "    dfsn.append(dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbtgeWxfnnnE"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32qsjTxuWISv"
   },
   "outputs": [],
   "source": [
    "def NN(X_train, y_train, neurons, activations, initializer,\n",
    "       optimizer, epochs, batch, loss, checkpoint=False): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train (Array): Variables independientes (muestra de entrenamiento)\n",
    "        y_train (Array): Variable dependiente (muestra de entrenamiento)\n",
    "        neurons (list): Número de neuronas en cada capa\n",
    "        activations (list): Función de activación en cada capa\n",
    "        initializer (str): Kernel initializer\n",
    "        optimizer (str): Optimizer\n",
    "        epochs (int): Número de epochs\n",
    "        batch (int): Tamaño de cada batch\n",
    "        loss (str): Función de pérdida\n",
    "        checkpoint (boolean): Si queremos que cada vez que haya mejora en un epoch se guarde el modelo\n",
    "\n",
    "    Returns:\n",
    "        model (modelo): Modelo de Red Neuronal\n",
    "    \"\"\"   \n",
    "    \n",
    "    dim = len(X_train[1])\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons[0], input_dim=dim, kernel_initializer=initializer,\n",
    "                    bias_initializer='zeros', activation=activations[0]))\n",
    "    \n",
    "    for i in range(1, len(neurons)):\n",
    "        model.add(Dense(neurons[i], kernel_initializer=initializer,\n",
    "                        bias_initializer='zeros', activation=activations[i]))\n",
    "        \n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    if checkpoint != False:\n",
    "        filepath = \"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "        callbacks_list = [checkpoint]\n",
    "\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch,\n",
    "                  callbacks=callbacks_list, validation_split=0.1)\n",
    "    \n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQPXGirSWIS6"
   },
   "outputs": [],
   "source": [
    "def model_precision(y_test, predictions, lim):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_test (array): Instancias de la variable dependiente\n",
    "        predictions (array): Predicciones\n",
    "        lim (float): Entre 0 y 1 que marca el límite de clasificación (arriba de lim se considera cierre)\n",
    "    \n",
    "    Returns:\n",
    "        Accuracy (float): (tp+tn)/(tp+tn+fp+fn)\n",
    "        Precision (float): tp/(tp+fp)\n",
    "        Recall (float): tp/(tp+fn)\n",
    "        F1_score (float): 2/(1/Precision+1/Recall) Media armónica entre Precision y Recall\n",
    "        MCC (float): Matthiews Correlation Coefficient (tp*tn-fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    \n",
    "    \"\"\"\n",
    "          \n",
    "    y_test.shape = [y_test.shape[0],1]\n",
    "    predictions.shape = [predictions.shape[0],1]\n",
    "    \n",
    "    test = np.concatenate((y_test, predictions),axis=1)\n",
    "\n",
    "    tp = ((test[:,0] == 1) & (test[:,1] >= lim)).sum()\n",
    "    fp = ((test[:,0] == 0) & (test[:,1] >= lim)).sum()\n",
    "    tn = ((test[:,0] == 0) & (test[:,1] < lim)).sum()\n",
    "    fn = ((test[:,0] == 1) & (test[:,1] < lim)).sum()\n",
    "    \n",
    "    Accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Precision = tp/(tp+fp)\n",
    "    Recall = tp/(tp+fn)\n",
    "    F1_score = 2/(1/Precision+1/Recall)\n",
    "    MCC = (tp*tn-fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    \n",
    "\n",
    "    res = pd.DataFrame(0, index=['Accuracy', 'Precision',\n",
    "                                     'Recall', 'F1 Score',\n",
    "                                     'MCC'], columns=['Score'])\n",
    "\n",
    "    res.loc['Accuracy'] = 100*Accuracy\n",
    "    res.loc['Precision'] = 100*Precision\n",
    "    res.loc['Recall'] = 100*Recall\n",
    "    res.loc['F1 Score'] = 100*F1_score\n",
    "    res.loc['MCC'] = 100*MCC\n",
    "    display(res)\n",
    "    \n",
    "    return Accuracy, Precision, Recall, F1_score, MCC\n",
    "\n",
    "def bucket_scores(y_test, predictions):\n",
    "    \"\"\"\n",
    "    Precision por cubeta de 10 en 10\n",
    "    \n",
    "    Args:\n",
    "        y_test (array): Instancias de la variable dependiente\n",
    "        predictions (array): Predicciones\n",
    "    \n",
    "    Returns:\n",
    "        res (DataFrame): Positive rate por scores de 1 a 100 en cubetas de 10\n",
    "    \n",
    "    \"\"\"\n",
    "    scoresindex = ['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80','80-90','90-100']\n",
    "    scorescolumns = ['Total','Positives']\n",
    "    res = pd.DataFrame(0, index=scoresindex, columns=scorescolumns)\n",
    "    \n",
    "    y_test.shape = [y_test.shape[0],1]\n",
    "    predictions.shape = [predictions.shape[0],1]\n",
    "    \n",
    "    test = np.concatenate((y_test,predictions),axis=1)\n",
    "    \n",
    "    low = 0\n",
    "    up = 0.1\n",
    "    for i in scoresindex:\n",
    "        res.loc[i]['Total'] = ((test[:,1] >= low) & (test[:,1] < up)).sum()\n",
    "        res.loc[i]['Positives'] = ((test[:,1] >= low) & (test[:,1] < up) & (test[:,0] == 1)).sum()\n",
    "        low += 0.1\n",
    "        up += 0.1\n",
    "    res['Positive Rate'] = res['Positives']/res['Total']*100  \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "xidIfRfymqm8",
    "outputId": "667239d6-3743-4066-d469-38fd68f2afba"
   },
   "outputs": [],
   "source": [
    "dfsn[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9348
    },
    "colab_type": "code",
    "id": "-BdwNF3Qga20",
    "outputId": "5103c181-eee9-4816-d266-e7c024399c4b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "import math\n",
    "\n",
    "nnmodels = []\n",
    "for i in range(len(dfsn)):\n",
    "    print(responsenn[i])\n",
    "    dfsn[i] = dfsn[i].dropna()\n",
    "    X_train, X_test, y_train, y_test = train_test(dfsn[i], responsenn[i], time_series=True)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler.fit(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    modelosnn = []\n",
    "    for j in range(10):\n",
    "        try:\n",
    "            k = round(abs(np.random.randn() * 10))\n",
    "            neurons = [X_train.shape[1]]\n",
    "            for s in range(k):\n",
    "                neurons.append(round(abs(np.random.randn() * 100)))\n",
    "            neurons.append(1)\n",
    "            activations = ['relu'] * (s + 1)\n",
    "            activations.append('sigmoid')\n",
    "            initializer = 'he_normal' \n",
    "            optimizer = 'adam'\n",
    "            loss = 'binary_crossentropy'\n",
    "            print('\\n Modelo #')\n",
    "            print(j)\n",
    "            print('\\n Neurons')\n",
    "            print(neurons)\n",
    "            print('\\n Initializer')\n",
    "            print(initializer)\n",
    "            print('\\n Optimizer')\n",
    "            print(optimizer)\n",
    "            print('\\n Loss')\n",
    "            print(loss)\n",
    "            mod = NN(X_train, y_train, neurons, activations, \n",
    "                                 initializer, optimizer, epochs=17, batch=512, loss=loss)\n",
    "            modelosnn.append(mod)\n",
    "            predictions_train = mod.predict(X_train)\n",
    "            predictions_test = mod.predict(X_test)\n",
    "\n",
    "\n",
    "            print('\\n -----------------------------------------')\n",
    "            lim = 0.5\n",
    "            Accuracy, Precision, Recall, F1_score, MCC = model_precision(y_test,predictions_test,lim)\n",
    "            bs = bucket_scores(y_test, predictions_test)\n",
    "            display(bs)  \n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, predictions_test, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
    "            plt.plot(fpr, tpr)\n",
    "            auc = np.trapz(tpr, fpr)\n",
    "            print('auc')\n",
    "            print(auc)\n",
    "\n",
    "            if auc > maxauc:\n",
    "                maxauc = auc\n",
    "                bestnn = j\n",
    "\n",
    "            plt.axis([0,1,0,1])\n",
    "            plt.plot([0,1],[0,1])\n",
    "            plt.show()\n",
    "        except:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-YfzXT3WISm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn6Z14y0WISz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rP-KYJtDWIS-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6uPUyveWITB",
    "outputId": "b2e0fac5-98c8-4eb0-c1cb-5191aebf32f1"
   },
   "outputs": [],
   "source": [
    "maxf1 = 0\n",
    "maxauc = 0\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "for i in modelosnn:\n",
    "            \n",
    "    predictions_train = i.predict(X_train)\n",
    "    predictions_test = i.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print('\\n -----------------------------------------')\n",
    "    lim = 0.5\n",
    "    Accuracy, Precision, Recall, F1_score, MCC = model_precision(y_test,predictions_test,lim)\n",
    "    bs = bucket_scores(y_test, predictions_test)\n",
    "    display(bs)  \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions_test, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
    "    plt.plot(fpr, tpr)\n",
    "    auc = np.trapz(tpr, fpr)\n",
    "    print('auc')\n",
    "    print(auc)\n",
    "    \n",
    "    if auc > maxauc:\n",
    "        maxauc = auc\n",
    "        bestnn = i\n",
    "\n",
    "plt.axis([0,1,0,1])\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4u7x4F0wWITH",
    "outputId": "785570b4-9e2f-42f6-e41d-e5e2b8711c67"
   },
   "outputs": [],
   "source": [
    "predictions_test = bestnn.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions_test, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
    "plt.plot(fpr, tpr, color='b', label='NN')\n",
    "\n",
    "plt.plot([0,1],[0,1], color='black', label='Pronóstico Aleatorio')\n",
    "\n",
    "plt.legend(prop={'size': 20})\n",
    "\n",
    "plt.axis([0,1,0,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('auc')\n",
    "print(np.trapz(tpr, fpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HiFhmLVWITO"
   },
   "outputs": [],
   "source": [
    "bestnn.save(responsenn+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTyE4cgPWITQ"
   },
   "source": [
    "# Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WcsXG9AWITQ"
   },
   "outputs": [],
   "source": [
    "response = oanda.get_history(instrument=\"USD_JPY\", granularity='M15', since='2018-08-23T01:00:00.00000Z')\n",
    "prices = response.get(\"prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99053
    },
    "colab_type": "code",
    "id": "kCOiErRwWITU",
    "outputId": "8a1cf1a1-36d7-4e1b-b316-d113ff33e67a"
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5paOJdGbWITd"
   },
   "outputs": [],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBG1VQPhWITg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUmbD0_-cmDi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Elite.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
